{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-12-7 Python-3.9.12 torch-1.12.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3070, 8192MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete  (16 CPUs, 15.8 GB RAM, 390.2/465.1 GB disk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-12-7 Python-3.9.12 torch-1.12.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3070, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 1760518 parameters, 0 gradients, 4.1 GFLOPs\n",
      "Adding AutoShape... \n",
      "YOLOv5  2022-12-7 Python-3.9.12 torch-1.12.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3070, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 1760518 parameters, 0 gradients, 4.1 GFLOPs\n",
      "Adding AutoShape... \n",
      "YOLOv5  2022-12-7 Python-3.9.12 torch-1.12.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3070, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
      "Adding AutoShape... \n",
      "YOLOv5  2022-12-7 Python-3.9.12 torch-1.12.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3070, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 117 layers, 4228176 parameters, 0 gradients, 10.4 GFLOPs\n",
      "WARNING  YOLOv5 ClassificationModel is not yet AutoShape compatible. You must pass torch tensors in BCHW to this model, i.e. shape(1,3,224,224).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#force to use CPU\n",
    "# torch.cuda.is_available = lambda : False\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import pathlib\n",
    "import time\n",
    "import os\n",
    "\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "import utils\n",
    "display = utils.notebook_init()\n",
    "\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import imutils as im\n",
    "from utils.dataloaders import LoadImages\n",
    "from utils.general import check_img_size\n",
    "from utils.augmentations import classify_transforms\n",
    "\n",
    "car_model = torch.hub.load('C:\\Project\\yolov5', 'custom', path='C:\\Project\\yolov5\\my_weight\\car_model_600.pt', source='local')\n",
    "\n",
    "license_model = torch.hub.load('C:\\Project\\yolov5', 'custom', path='C:\\Project\\yolov5\\my_weight\\license_object_detection_500_real.pt', source='local')\n",
    "\n",
    "model = torch.hub.load('C:\\Project\\yolov5', 'custom', path='C:\\Project\\yolov5\\my_weight\\letter_object_nano_all_real_final.pt', source='local')\n",
    "\n",
    "classification_model = torch.hub.load('C:\\Project\\yolov5', 'custom', path='C:\\Project\\yolov5\\my_weight\\letter_class_real_100epoch_big.pt', source='local')\n",
    "\n",
    "alphabet_dict = {\n",
    "    \"0E01\": \"ก\",\n",
    "    \"0E02\": \"ข\",\n",
    "    \"0E04\": \"ค\",\n",
    "    \"0E06\": \"ฆ\",\n",
    "    \"0E07\": \"ง\",\n",
    "    \"0E08\": \"จ\",\n",
    "    \"0E09\": \"ฉ\",\n",
    "    \"0E0A\": \"ช\",\n",
    "    \"0E0C\": \"ฌ\",\n",
    "    \"0E0D\": \"ญ\",\n",
    "    \"0E0E\": \"ฎ\",\n",
    "    \"0E10\": \"ฐ\",\n",
    "    \"0E12\": \"ฒ\",\n",
    "    \"0E13\": \"ณ\",\n",
    "    \"0E14\": \"ด\",\n",
    "    \"0E15\": \"ต\",\n",
    "    \"0E16\": \"ถ\",\n",
    "    \"0E17\": \"ท\",\n",
    "    \"0E18\": \"ธ\",\n",
    "    \"0E19\": \"น\",\n",
    "    \"0E1A\": \"บ\",\n",
    "    \"0E1B\": \"ป\",\n",
    "    \"0E1C\": \"ผ\",\n",
    "    \"0E1E\": \"พ\",\n",
    "    \"0E1F\": \"ฟ\",\n",
    "    \"0E20\": \"ภ\",\n",
    "    \"0E21\": \"ม\",\n",
    "    \"0E22\": \"ย\",\n",
    "    \"0E23\": \"ร\",\n",
    "    \"0E25\": \"ล\",\n",
    "    \"0E27\": \"ว\",\n",
    "    \"0E28\": \"ศ\",\n",
    "    \"0E29\": \"ษ\",\n",
    "    \"0E2A\": \"ส\",\n",
    "    \"0E2B\": \"ห\",\n",
    "    \"0E2C\": \"ฬ\",\n",
    "    \"0E2D\": \"อ\",\n",
    "    \"0E2E\": \"ฮ\",\n",
    "    \"n0\": \"0\",\n",
    "    \"n1\":\"1\",\n",
    "    \"n2\":\"2\",\n",
    "    \"n3\":\"3\",\n",
    "    \"n4\":\"4\",\n",
    "    \"n5\":\"5\",\n",
    "    \"n6\":\"6\",\n",
    "    \"n7\":\"7\",\n",
    "    \"n8\":\"8\",\n",
    "    \"n9\":\"9\"\n",
    "}\n",
    "number_list = [\"n1\",\"n2\",\"n3\",\"n4\",\"n5\",\"n6\",\"n7\",\"n8\",\"n9\",\"n0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "กธ4856 6\n",
      "กธ4856 6\n",
      "กธ4856 6\n",
      "กธ4856 6\n",
      "กธ4856 6\n",
      "9กญ719 6\n",
      "9กญ719 6\n",
      "9กญ719 6\n",
      "165029 6\n",
      "165029 6\n",
      "165029 6\n",
      "3กฆ5199 7\n",
      "3กฆ5199 7\n",
      "3กฆ5199 7\n",
      "3กฆ5199 7\n",
      "4กฌ9728 7\n",
      "4กฌ9728 7\n",
      "4กฌ9728 7\n",
      "ทส4465 6\n",
      "ทส4465 6\n",
      "ทส4465 6\n",
      "ภฐ65 4\n",
      "ภฐ65 4\n",
      "ภฐ65 4\n",
      "ภฐ65 4\n",
      "กพ7118 6\n",
      "กพ7118 6\n",
      "กพ7118 6\n",
      "กพ7118 6\n",
      "กง6123 6\n",
      "กง6123 6\n",
      "กง6123 6\n",
      "9กด7411 7\n",
      "9กด7411 7\n",
      "9กด7411 7\n",
      "9กด7411 7\n",
      "9กด7411 7\n",
      "9กด7411 7\n",
      "9กด7411 7\n",
      "9กด7411 7\n",
      "9กด7411 7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from mss import mss\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import io\n",
    "\n",
    "sct = mss()\n",
    "global_count=0\n",
    "\n",
    "while 1:\n",
    "    w, h = 1920, 1080\n",
    "    sw, sh = 0,0\n",
    "    monitor = {'top': sh, 'left': sw, 'width': w-sw, 'height': h-sh}\n",
    "    sct_img = sct.grab(monitor)\n",
    "    img = Image.frombytes('RGB', sct_img.size, sct_img.rgb)\n",
    "    cv2.namedWindow(\"test\", cv2.WINDOW_NORMAL)\n",
    "    # Resize this window\n",
    "    cv2.resizeWindow(\"test\", int((w-sw)*0.6), int((h-sh)*0.6))\n",
    "    cv2.imshow('test', cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    results = car_model(img)\n",
    "    dfResults = results.pandas().xyxy[0]\n",
    "    #check if there is at least one car detected\n",
    "    if len(dfResults) > 0:\n",
    "      image = img\n",
    "      image_arr = np.array(image)\n",
    "      #choose car start at 0\n",
    "      letter_index=0\n",
    "      x1=int(results.xyxy[0][letter_index][0])\n",
    "      x2=int(results.xyxy[0][letter_index][2])\n",
    "      y1=int(results.xyxy[0][letter_index][1])\n",
    "      y2=int(results.xyxy[0][letter_index][3])\n",
    "      image_arr2 = image_arr[y1:y2, x1:x2]\n",
    "      save_img_car = Image.fromarray(image_arr2)\n",
    "      save_img_car = save_img_car.convert('RGB')\n",
    "    #   save_img_car.save('./my_output/'+str(global_count)+'_crop_car.jpg')\n",
    "    #   global_count+=1\n",
    "\n",
    "      results = license_model(image_arr2)\n",
    "      dfResults = results.pandas().xyxy[0]\n",
    "      #check if there is at least one license plate detected\n",
    "      if len(dfResults) > 0:\n",
    "          #gray scale\n",
    "          image = Image.fromarray(image_arr2)\n",
    "          image = image.convert('L')\n",
    "          image_arr = np.array(image)\n",
    "          #choose license plate start at 0\n",
    "          letter_index=0\n",
    "          #check if detected plate width is > height\n",
    "          while len(results.xyxy[0]) > letter_index:\n",
    "            x1=int(results.xyxy[0][letter_index][0])\n",
    "            x2=int(results.xyxy[0][letter_index][2])\n",
    "            y1=int(results.xyxy[0][letter_index][1])\n",
    "            y2=int(results.xyxy[0][letter_index][3])\n",
    "            if (x2-x1) > (y2-y1):\n",
    "              image_arr2 = image_arr[y1:y2, x1:x2]\n",
    "              break\n",
    "            letter_index+=1\n",
    "\n",
    "          def image_resize(image, width = None, height = None, inter = cv2.INTER_CUBIC):\n",
    "              dim = None\n",
    "              (h, w) = image.shape[:2]\n",
    "              if width is None and height is None:\n",
    "                  return image\n",
    "              if width is None:\n",
    "                  r = height / float(h)\n",
    "                  dim = (int(w * r), height)\n",
    "              else:\n",
    "                  r = width / float(w)\n",
    "                  dim = (width, int(h * r))\n",
    "              resized = cv2.resize(image, dim, interpolation = inter)\n",
    "              return resized\n",
    "          save_img = image_resize(image_arr2, height = 100)\n",
    "          save_img = cv2.fastNlMeansDenoising(save_img, None, 20, 7, 21)\n",
    "          kernel = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])\n",
    "          save_img = cv2.filter2D(save_img, -1, kernel)\n",
    "          cv2.imwrite('./crop_img2.jpg',save_img)\n",
    "\n",
    "          #letter_province\n",
    "          results = model(save_img)\n",
    "          dfResults = results.pandas().xyxy[0]\n",
    "\n",
    "          count_letter=len(results.xyxy[0])\n",
    "          if(torch.cuda.is_available()):\n",
    "              xmin_sort=torch.tensor([]).to('cuda')\n",
    "          else:\n",
    "              xmin_sort=torch.tensor([]).to('cpu')\n",
    "          for i in range(count_letter):\n",
    "              #convert from dim0 to dim1\n",
    "              if(torch.cuda.is_available()):\n",
    "                  xmin=torch.tensor([results.xyxy[0][i][0]]).to('cuda')\n",
    "              else:\n",
    "                  xmin=torch.tensor([results.xyxy[0][i][0]]).to('cpu')\n",
    "              xmin_sort=torch.cat((xmin_sort,xmin),0)\n",
    "          xmin_sorted, _ = torch.sort(xmin_sort)\n",
    "\n",
    "\n",
    "          #Letter_object detection extract\n",
    "\n",
    "          if len(results.pandas().xyxy[0]) > 0:\n",
    "              image_arr = save_img\n",
    "              #image_arr[y1:y2, x1:x2]\n",
    "              license_string_list=[]\n",
    "              string_count=0\n",
    "              letter_index=0\n",
    "              while letter_index<count_letter:\n",
    "                my_index=0\n",
    "                while my_index < count_letter:\n",
    "                  if xmin_sorted[letter_index] == results.xyxy[0][my_index][0]:\n",
    "                    if results.xyxy[0][my_index][5] < 1:\n",
    "                      x1=int(results.xyxy[0][my_index][0])\n",
    "                      x2=int(results.xyxy[0][my_index][2])\n",
    "                      y1=int(results.xyxy[0][my_index][1])\n",
    "                      y2=int(results.xyxy[0][my_index][3])\n",
    "                      image_arr2 = image_arr[y1:y2, x1:x2]\n",
    "\n",
    "                      #resize to 224x224 before put into the model\n",
    "                      image_arr2 = cv2.resize(image_arr2, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "                      save_img4 = Image.fromarray(image_arr2)\n",
    "                      save_img4.save(\"./my_output/crop_alphabet/crop_alphabet\"+str(string_count)+\".jpg\")\n",
    "\n",
    "                      ### Clasification Model ###\n",
    "                      img_path = \"./my_output/crop_alphabet/crop_alphabet\"+str(string_count)+\".jpg\"\n",
    "                      stride = classification_model.stride\n",
    "                      vid_stride=1\n",
    "                      imgsz=(224, 224)\n",
    "                      imgsz = check_img_size(imgsz, s=stride)\n",
    "                      dataset = LoadImages(img_path, img_size=imgsz, transforms=classify_transforms(imgsz[0]), vid_stride=vid_stride)\n",
    "                      for _, im, _, _, s in dataset:\n",
    "                        img = im\n",
    "                      #add batch to image array\n",
    "                      img = img.unsqueeze(0)\n",
    "                      #add image array to tensor store in Nvidia vram\n",
    "                      if(torch.cuda.is_available()):\n",
    "                        img = torch.Tensor(img).to('cuda')\n",
    "                      else:\n",
    "                        img = torch.Tensor(img).to('cpu')\n",
    "\n",
    "                      img = img.half() if classification_model.fp16 else img.float()\n",
    "                      if len(img.shape) == 3:\n",
    "                        img = img[None]\n",
    "                      #input to model\n",
    "                      names = classification_model.names\n",
    "                      classification_results = classification_model(img)\n",
    "                      pred = F.softmax(classification_results, dim=1)\n",
    "                      for i, prob in enumerate(pred):\n",
    "                        top3i = prob.argsort(0, descending=True)[:2].tolist()\n",
    "                      mark=0\n",
    "                      for i in top3i:\n",
    "                        if mark==0:\n",
    "                          if(prob[i]>=0.1):\n",
    "                            license_string_list.append(names[i])\n",
    "                          mark=1\n",
    "                      letter_index=letter_index+1\n",
    "                      my_index=count_letter\n",
    "                      string_count+=1\n",
    "                    else:\n",
    "                      letter_index=letter_index+1\n",
    "                  my_index=my_index+1\n",
    "\n",
    "              license_len = len(license_string_list)\n",
    "              check=True\n",
    "\n",
    "              license_string=\"\"\n",
    "              for i in license_string_list:\n",
    "                license_string=license_string+alphabet_dict[i]\n",
    "              print(license_string,license_len)\n",
    "\n",
    "\n",
    "              timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "              try:\n",
    "                os.mkdir(\"./my_output/\"+license_string)\n",
    "                cv2.imwrite('./my_output/'+license_string+\"/\"+license_string+\"-\"+timestr+'.jpg',save_img)\n",
    "                save_img_car.save('./my_output/'+license_string+\"/car_\"+license_string+\"-\"+timestr+'.jpg')\n",
    "              except:\n",
    "                cv2.imwrite('./my_output/'+license_string+\"/\"+license_string+\"-\"+timestr+'.jpg',save_img)\n",
    "                save_img_car.save('./my_output/'+license_string+\"/car_\"+license_string+\"-\"+timestr+'.jpg')\n",
    "\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
