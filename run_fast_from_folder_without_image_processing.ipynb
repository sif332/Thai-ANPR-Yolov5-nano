{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-12-7 Python-3.9.12 torch-1.12.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3070, 8192MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete  (16 CPUs, 15.8 GB RAM, 390.4/465.1 GB disk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-12-7 Python-3.9.12 torch-1.12.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3070, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 1760518 parameters, 0 gradients, 4.1 GFLOPs\n",
      "Adding AutoShape... \n",
      "YOLOv5  2022-12-7 Python-3.9.12 torch-1.12.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3070, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 1760518 parameters, 0 gradients, 4.1 GFLOPs\n",
      "Adding AutoShape... \n",
      "YOLOv5  2022-12-7 Python-3.9.12 torch-1.12.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3070, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
      "Adding AutoShape... \n",
      "YOLOv5  2022-12-7 Python-3.9.12 torch-1.12.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3070, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 117 layers, 4228176 parameters, 0 gradients, 10.4 GFLOPs\n",
      "WARNING  YOLOv5 ClassificationModel is not yet AutoShape compatible. You must pass torch tensors in BCHW to this model, i.e. shape(1,3,224,224).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#force to use CPU\n",
    "# torch.cuda.is_available = lambda : False\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import pathlib\n",
    "import time\n",
    "import os\n",
    "\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "import utils\n",
    "display = utils.notebook_init()\n",
    "\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import imutils as im\n",
    "from utils.dataloaders import LoadImages\n",
    "from utils.general import check_img_size\n",
    "from utils.augmentations import classify_transforms\n",
    "\n",
    "car_model = torch.hub.load('C:\\Project\\yolov5', 'custom', path='C:\\Project\\yolov5\\my_weight\\car_model_600.pt', source='local')\n",
    "\n",
    "license_model = torch.hub.load('C:\\Project\\yolov5', 'custom', path='C:\\Project\\yolov5\\my_weight\\license_object_detection_500_real.pt', source='local')\n",
    "\n",
    "model = torch.hub.load('C:\\Project\\yolov5', 'custom', path='C:\\Project\\yolov5\\my_weight\\letter_object_nano_all_real_final.pt', source='local')\n",
    "\n",
    "classification_model = torch.hub.load('C:\\Project\\yolov5', 'custom', path='C:\\Project\\yolov5\\my_weight\\letter_class_real_100epoch_big.pt', source='local')\n",
    "\n",
    "alphabet_dict = {\n",
    "    \"0E01\": \"ก\",\n",
    "    \"0E02\": \"ข\",\n",
    "    \"0E04\": \"ค\",\n",
    "    \"0E06\": \"ฆ\",\n",
    "    \"0E07\": \"ง\",\n",
    "    \"0E08\": \"จ\",\n",
    "    \"0E09\": \"ฉ\",\n",
    "    \"0E0A\": \"ช\",\n",
    "    \"0E0C\": \"ฌ\",\n",
    "    \"0E0D\": \"ญ\",\n",
    "    \"0E0E\": \"ฎ\",\n",
    "    \"0E10\": \"ฐ\",\n",
    "    \"0E12\": \"ฒ\",\n",
    "    \"0E13\": \"ณ\",\n",
    "    \"0E14\": \"ด\",\n",
    "    \"0E15\": \"ต\",\n",
    "    \"0E16\": \"ถ\",\n",
    "    \"0E17\": \"ท\",\n",
    "    \"0E18\": \"ธ\",\n",
    "    \"0E19\": \"น\",\n",
    "    \"0E1A\": \"บ\",\n",
    "    \"0E1B\": \"ป\",\n",
    "    \"0E1C\": \"ผ\",\n",
    "    \"0E1E\": \"พ\",\n",
    "    \"0E1F\": \"ฟ\",\n",
    "    \"0E20\": \"ภ\",\n",
    "    \"0E21\": \"ม\",\n",
    "    \"0E22\": \"ย\",\n",
    "    \"0E23\": \"ร\",\n",
    "    \"0E25\": \"ล\",\n",
    "    \"0E27\": \"ว\",\n",
    "    \"0E28\": \"ศ\",\n",
    "    \"0E29\": \"ษ\",\n",
    "    \"0E2A\": \"ส\",\n",
    "    \"0E2B\": \"ห\",\n",
    "    \"0E2C\": \"ฬ\",\n",
    "    \"0E2D\": \"อ\",\n",
    "    \"0E2E\": \"ฮ\",\n",
    "    \"n0\": \"0\",\n",
    "    \"n1\":\"1\",\n",
    "    \"n2\":\"2\",\n",
    "    \"n3\":\"3\",\n",
    "    \"n4\":\"4\",\n",
    "    \"n5\":\"5\",\n",
    "    \"n6\":\"6\",\n",
    "    \"n7\":\"7\",\n",
    "    \"n8\":\"8\",\n",
    "    \"n9\":\"9\"\n",
    "}\n",
    "number_list = [\"n1\",\"n2\",\"n3\",\"n4\",\"n5\",\"n6\",\"n7\",\"n8\",\"n9\",\"n0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "กง1111 6\n",
      "6กฬ2926 7\n",
      "ชจ6811 6\n",
      "3ฒถ5152 7\n",
      "4กส9470 7\n",
      "5กส3591 7\n",
      "2ขร4266 7\n",
      "1ขง7746 7\n",
      "ฌร6523 6\n",
      "1มช6177 7\n",
      "2ขน2543 7\n",
      "5กฎ7433 7\n",
      "ฒพ6590 6\n",
      "กท9279 6\n",
      "ญฉ2375 6\n",
      "ภษ6210 6\n",
      "ทฬ4136 6\n",
      "กต3165 6\n",
      "4กพ6839 7\n",
      "8กด9532 7\n",
      "1มค7827 7\n",
      "3ฒฒ912 6\n",
      "2ขฐ7728 7\n",
      "ฮง8709 6\n",
      "2ขษ8531 7\n",
      "5กฉ4703 7\n",
      "ฮร4841 6\n",
      "ทส5962 6\n",
      "สท4114 6\n",
      "3กอ6864 7\n",
      "7กง9436 7\n",
      "8กถ5997 7\n",
      "4กผ7265 7\n",
      "6กผ5037 7\n",
      "กต4104 6\n",
      "2กม5502 7\n",
      "8กง4820 7\n",
      "กธ978 5\n",
      "ฒบ5367 6\n",
      "ญถ7664 6\n",
      "8กส2919 7\n",
      "9กท7538 7\n",
      "4กบ519 6\n",
      "1ฒพ6140 7\n",
      "ษม3627 6\n",
      "ญณ8874 6\n",
      "4กธ6834 7\n",
      "ฆส9658 6\n",
      "ทส1863 6\n",
      "กม9189 6\n",
      "1กค801 6\n",
      "ภฉ5678 6\n",
      "2ขว3561 7\n",
      "824947 6\n",
      "1ขจ4819 7\n",
      "ถฬ6410 6\n",
      "1กถ8356 7\n",
      "ทส2149 6\n",
      "1ฒน5554 7\n",
      "กฉ9999 6\n",
      "3กล9219 7\n",
      "1ขณ5876 7\n",
      "3ฒฉ894 6\n",
      "9กญ719 6\n",
      "1ขค1446 7\n",
      "ฆส4341 6\n",
      "2ขธ9104 7\n",
      "2ฒฒ2752 7\n",
      "162403 6\n",
      "1ขง2646 7\n",
      "ฬ6656 5\n",
      "2ฒข8079 7\n",
      "ษช756 5\n",
      "6กร5995 7\n",
      "102089 6\n",
      "ถณ9351 6\n",
      "สท5720 6\n",
      "ฆศ5889 6\n",
      "7กญ3546 7\n",
      "ผ2178 5\n",
      "1มข9278 7\n",
      "162397 6\n",
      "5กฉ1607 7\n",
      "9กฐ6955 7\n",
      "1ฒฐ5325 7\n",
      "5กธ9769 7\n",
      "บว3006 6\n",
      "บธ5359 6\n",
      "3ฒฒ670 6\n",
      "กค6269 6\n",
      "162136 6\n",
      "กอ6988 6\n",
      "ทฬ9148 6\n",
      "ขข405 5\n",
      "1ฒศ2415 7\n",
      "3กว279 6\n",
      "นข7191 6\n",
      "กต4129 6\n",
      "161428 6\n",
      "162405 6\n",
      "2ขด6351 7\n",
      "ฆธ6358 6\n",
      "2กถ4009 7\n",
      "8กฬ8343 7\n",
      "3ขฆ5867 7\n",
      "กษ6564 6\n",
      "ชถ8880 6\n",
      "ชช8524 6\n",
      "9กบ8817 7\n",
      "ฆง2699 6\n",
      "1กข9436 7\n",
      "ฌธ9115 6\n",
      "1ฒว9996 7\n",
      "2ขฌ9027 7\n",
      "9กธ2116 7\n",
      "1กฒ2620 7\n",
      "7กณ9860 7\n",
      "1นก3964 7\n",
      "9กถ1316 7\n",
      "5กจ4515 7\n",
      "2ชณ5429 7\n",
      "2ขฉ6766 7\n",
      "ฮร1910 6\n",
      "1มข9798 7\n",
      "งน6333 6\n",
      "ฒภ5536 6\n",
      "ถอ9196 6\n",
      "6กด6815 7\n",
      "ฒพ6590 6\n",
      "ฮก9301 6\n",
      "กจ4884 6\n",
      "2กง4382 7\n",
      "1นก2001 7\n",
      "ศศ8985 6\n",
      "ฮว4541 6\n",
      "กค3276 6\n",
      "8กข1975 7\n",
      "ฆธ9266 6\n",
      "ฒฌ657 5\n",
      "6กง3371 7\n",
      "2กฮ1235 7\n",
      "ฮอ3101 6\n",
      "กจ683 5\n",
      "5กถ5351 7\n",
      "1ชต1460 7\n",
      "1ฎ3888 6\n",
      "ฌห5059 6\n",
      "กจ2481 6\n",
      "กม4399 6\n",
      "8กจ7345 7\n",
      "1กว5634 7\n",
      "3กฮ5886 7\n",
      "825864 6\n",
      "ฎท5365 6\n",
      "9กบ5706 7\n",
      "2กก1พ260 8\n",
      "กย3247 6\n",
      "1ขร200 6\n",
      "ชช3596 6\n",
      "3ฒข5805 7\n",
      "ฮล1365 6\n",
      "กธ8495 6\n",
      "กธ6414 6\n",
      "ฮง6934 6\n",
      "1นก3160 7\n",
      "9ฐฐ929 6\n",
      "1ขร4092 7\n",
      "กท2947 6\n",
      "ฆม7641 6\n",
      "3กฮ9089 7\n",
      "2กร5745 7\n",
      "กง7129 6\n",
      "ฒฒ6294 6\n",
      "6กณ5321 7\n",
      "4กข8785 7\n",
      "ฌส9877 6\n",
      "กท1996 6\n",
      "ณ7047 5\n",
      "กค5658 6\n",
      "4กล3630 7\n",
      "ชช712 5\n",
      "2กข7592 7\n",
      "6กธ357 6\n",
      "162125 6\n",
      "4กฎ4117 7\n",
      "กอ4928 6\n",
      "7กด2270 7\n",
      "3กฌ6876 7\n",
      "8กร3428 7\n",
      "343350 6\n",
      "2ขฌ2787 7\n",
      "กฉ3221 6\n",
      "กฉ6931 6\n",
      "8กฬ4999 7\n",
      "กว3737 6\n",
      "3กด3935 7\n",
      "2กฆ1916 7\n",
      "2กฐ3221 7\n",
      "กษ2989 6\n",
      "5กช5449 7\n"
     ]
    }
   ],
   "source": [
    "#run by input images from folder name \"test_folder\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import glob\n",
    "import time\n",
    "\n",
    "filenames = glob.glob(\"./test_folder/*.jpg\")\n",
    "filenames.sort()\n",
    "images = [Image.open(img) for img in filenames]\n",
    "\n",
    "global_count=0\n",
    "for img in images:\n",
    "    results = car_model(img)\n",
    "    dfResults = results.pandas().xyxy[0]\n",
    "    #check if there is at least one car detected\n",
    "    if len(dfResults) > 0:\n",
    "      image = img\n",
    "      image_arr = np.array(image)\n",
    "      #choose car start at 0\n",
    "      letter_index=0\n",
    "      x1=int(results.xyxy[0][letter_index][0])\n",
    "      x2=int(results.xyxy[0][letter_index][2])\n",
    "      y1=int(results.xyxy[0][letter_index][1])\n",
    "      y2=int(results.xyxy[0][letter_index][3])\n",
    "      image_arr2 = image_arr[y1:y2, x1:x2]\n",
    "      save_img_car = Image.fromarray(image_arr2)\n",
    "      save_img_car = save_img_car.convert('RGB')\n",
    "      save_img_car.save('./my_output/'+str(global_count)+'_crop_car.jpg')\n",
    "      global_count+=1\n",
    "\n",
    "      results = license_model(image_arr2)\n",
    "      dfResults = results.pandas().xyxy[0]\n",
    "      #check if there is at least one license plate detected\n",
    "      if len(dfResults) > 0:\n",
    "          #gray scale\n",
    "          image = Image.fromarray(image_arr2)\n",
    "          image = image.convert('L')\n",
    "          image_arr = np.array(image)\n",
    "          #choose license plate start at 0\n",
    "          letter_index=0\n",
    "          #check if detected plate width is > height\n",
    "          while len(results.xyxy[0]) > letter_index:\n",
    "            x1=int(results.xyxy[0][letter_index][0])\n",
    "            x2=int(results.xyxy[0][letter_index][2])\n",
    "            y1=int(results.xyxy[0][letter_index][1])\n",
    "            y2=int(results.xyxy[0][letter_index][3])\n",
    "            if (x2-x1) > (y2-y1):\n",
    "              image_arr2 = image_arr[y1:y2, x1:x2]\n",
    "              break\n",
    "            letter_index+=1\n",
    "\n",
    "          # def image_resize(image, width = None, height = None, inter = cv2.INTER_CUBIC):\n",
    "          #     dim = None\n",
    "          #     (h, w) = image.shape[:2]\n",
    "          #     if width is None and height is None:\n",
    "          #         return image\n",
    "          #     if width is None:\n",
    "          #         r = height / float(h)\n",
    "          #         dim = (int(w * r), height)\n",
    "          #     else:\n",
    "          #         r = width / float(w)\n",
    "          #         dim = (width, int(h * r))\n",
    "          #     resized = cv2.resize(image, dim, interpolation = inter)\n",
    "          #     return resized\n",
    "          # save_img = image_resize(image_arr2, height = 100)\n",
    "          # save_img = cv2.fastNlMeansDenoising(save_img, None, 20, 7, 21)\n",
    "          # kernel = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])\n",
    "          # save_img = cv2.filter2D(save_img, -1, kernel)\n",
    "          save_img=image_arr2\n",
    "          cv2.imwrite('./crop_img2.jpg',save_img)\n",
    "\n",
    "          #letter_province\n",
    "          results = model(save_img)\n",
    "          dfResults = results.pandas().xyxy[0]\n",
    "\n",
    "          count_letter=len(results.xyxy[0])\n",
    "          if(torch.cuda.is_available()):\n",
    "              xmin_sort=torch.tensor([]).to('cuda')\n",
    "          else:\n",
    "              xmin_sort=torch.tensor([]).to('cpu')\n",
    "          for i in range(count_letter):\n",
    "              #convert from dim0 to dim1\n",
    "              if(torch.cuda.is_available()):\n",
    "                  xmin=torch.tensor([results.xyxy[0][i][0]]).to('cuda')\n",
    "              else:\n",
    "                  xmin=torch.tensor([results.xyxy[0][i][0]]).to('cpu')\n",
    "              xmin_sort=torch.cat((xmin_sort,xmin),0)\n",
    "          xmin_sorted, _ = torch.sort(xmin_sort)\n",
    "\n",
    "\n",
    "          #Letter_object detection extract\n",
    "\n",
    "          if len(results.pandas().xyxy[0]) > 0:\n",
    "              image_arr = save_img\n",
    "              #image_arr[y1:y2, x1:x2]\n",
    "              license_string_list=[]\n",
    "              string_count=0\n",
    "              letter_index=0\n",
    "              while letter_index<count_letter:\n",
    "                my_index=0\n",
    "                while my_index < count_letter:\n",
    "                  if xmin_sorted[letter_index] == results.xyxy[0][my_index][0]:\n",
    "                    if results.xyxy[0][my_index][5] < 1:\n",
    "                      x1=int(results.xyxy[0][my_index][0])\n",
    "                      x2=int(results.xyxy[0][my_index][2])\n",
    "                      y1=int(results.xyxy[0][my_index][1])\n",
    "                      y2=int(results.xyxy[0][my_index][3])\n",
    "                      image_arr2 = image_arr[y1:y2, x1:x2]\n",
    "\n",
    "                      #resize to 224x224 before put into the model\n",
    "                      image_arr2 = cv2.resize(image_arr2, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "                      save_img4 = Image.fromarray(image_arr2)\n",
    "                      save_img4.save(\"./my_output/crop_alphabet/crop_alphabet\"+str(string_count)+\".jpg\")\n",
    "\n",
    "                      ### Clasification Model ###\n",
    "                      img_path = \"./my_output/crop_alphabet/crop_alphabet\"+str(string_count)+\".jpg\"\n",
    "                      stride = classification_model.stride\n",
    "                      vid_stride=1\n",
    "                      imgsz=(224, 224)\n",
    "                      imgsz = check_img_size(imgsz, s=stride)\n",
    "                      dataset = LoadImages(img_path, img_size=imgsz, transforms=classify_transforms(imgsz[0]), vid_stride=vid_stride)\n",
    "                      for _, im, _, _, s in dataset:\n",
    "                        img = im\n",
    "                      #add batch to image array\n",
    "                      img = img.unsqueeze(0)\n",
    "                      #add image array to tensor store in Nvidia vram\n",
    "                      if(torch.cuda.is_available()):\n",
    "                        img = torch.Tensor(img).to('cuda')\n",
    "                      else:\n",
    "                        img = torch.Tensor(img).to('cpu')\n",
    "\n",
    "                      img = img.half() if classification_model.fp16 else img.float()\n",
    "                      if len(img.shape) == 3:\n",
    "                        img = img[None]\n",
    "                      #input to model\n",
    "                      names = classification_model.names\n",
    "                      classification_results = classification_model(img)\n",
    "                      pred = F.softmax(classification_results, dim=1)\n",
    "                      for i, prob in enumerate(pred):\n",
    "                        top3i = prob.argsort(0, descending=True)[:2].tolist()\n",
    "                      mark=0\n",
    "                      for i in top3i:\n",
    "                        if mark==0:\n",
    "                          if(prob[i]>=0.1):\n",
    "                            license_string_list.append(names[i])\n",
    "                          mark=1\n",
    "                      letter_index=letter_index+1\n",
    "                      my_index=count_letter\n",
    "                      string_count+=1\n",
    "                    else:\n",
    "                      letter_index=letter_index+1\n",
    "                  my_index=my_index+1\n",
    "\n",
    "              license_len = len(license_string_list)\n",
    "              check=True\n",
    "\n",
    "              license_string=\"\"\n",
    "              for i in license_string_list:\n",
    "                license_string=license_string+alphabet_dict[i]\n",
    "              print(license_string,license_len)\n",
    "\n",
    "\n",
    "              timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "              try:\n",
    "                os.mkdir(\"./my_output/\"+license_string)\n",
    "                cv2.imwrite('./my_output/'+license_string+\"/\"+license_string+\"-\"+timestr+'.jpg',save_img)\n",
    "                save_img_car.save('./my_output/'+license_string+\"/car_\"+license_string+\"-\"+timestr+'.jpg')\n",
    "              except:\n",
    "                cv2.imwrite('./my_output/'+license_string+\"/\"+license_string+\"-\"+timestr+'.jpg',save_img)\n",
    "                save_img_car.save('./my_output/'+license_string+\"/car_\"+license_string+\"-\"+timestr+'.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
